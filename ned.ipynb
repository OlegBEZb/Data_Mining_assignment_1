{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67aba480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pmdarima as pm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ValueWarning\n",
    "warnings.simplefilter('ignore', ValueWarning)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c61665",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "* TODO: do the same NA handling as Oleg and Agoston for consistency..,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4558af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mood.csv\")\n",
    "\n",
    "# We only care about mood for ARIMA, so we drop other variables\n",
    "df = df[df.variable == 'mood']\n",
    "\n",
    "# We keep the id, timestamp, and value for mood\n",
    "df = df[['id', 'time', 'value']]\n",
    "\n",
    "# We change the time strings to datetime objjects\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Setting the index as the time\n",
    "df.set_index('time', inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# We rename the value column to mood since it only contains values for mood now\n",
    "df = df.rename(columns={'value': 'mood'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73871bfe",
   "metadata": {},
   "source": [
    "## Separating the data\n",
    "* First we will separate for each participant\n",
    "* Then we will do a train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c12b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data for each participant\n",
    "participants = {participant: df[df.id == participant].drop(['id'], axis=1) for participant in df.id.unique()}\n",
    "\n",
    "# Maps each participants to a train and test set\n",
    "train_test_dict = {}\n",
    "for participant in participants:\n",
    "    cutoff = int(len(participants[participant]['mood']) * 0.8)\n",
    "    train = participants[participant]['mood'][:cutoff]\n",
    "    test = participants[participant]['mood'][cutoff:]\n",
    "    \n",
    "#     time_index_train = participants[participant]['time'][:cutoff]\n",
    "#     time_index_test = participants[participant]['time'][cutoff:]\n",
    "    \n",
    "    train_test_dict[participant] = {'train': train, 'test': test, 'cutoff': cutoff}\n",
    "#     train_test_dict[participant] = {'train': train, 'test': test, 'time_index_train': time_index_train, 'time_index_test': time_index_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe002480",
   "metadata": {},
   "source": [
    "## Finding the models with the optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd67c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_test_dict['AS14.01']['train']\n",
    "\n",
    "# Maps each participant to a fitted model\n",
    "model_dict = {}\n",
    "for participant in participants:\n",
    "    train = train_test_dict[participant]['train']\n",
    "    \n",
    "    model = pm.auto_arima(train, start_p=1, start_q=1,\n",
    "                          test='adf',       # use adftest to find optimal 'd'\n",
    "                          max_p=5, max_q=5, # maximum p and q\n",
    "                          m=1,              # frequency of series\n",
    "                          d=None,           # let model determine 'd'\n",
    "                          seasonal=False,   # No Seasonality (Might have to check for this shit?)\n",
    "                          start_P=0, \n",
    "                          D=0, \n",
    "                          trace=False,\n",
    "                          error_action='ignore',  \n",
    "                          suppress_warnings=True, \n",
    "                          stepwise=True)\n",
    "    model_dict[participant] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c3e57",
   "metadata": {},
   "source": [
    "## Using the statsmodels package ARIMA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "166aeaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n"
     ]
    }
   ],
   "source": [
    "final_models = {}\n",
    "fitted_models = {}\n",
    "for participant in model_dict.keys():\n",
    "    order = model_dict[participant].order\n",
    "    endog = train_test_dict[participant]['train']\n",
    "    model = ARIMA(endog=endog, order=order)\n",
    "    \n",
    "    final_models[participant] = model\n",
    "    \n",
    "    fitted_models[participant] = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74354edd",
   "metadata": {},
   "source": [
    "## Predicting with each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c85a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dict = {}\n",
    "for participant in participants:\n",
    "    # Get the correct model\n",
    "    model = fitted_models[participant]\n",
    "    \n",
    "    # Get the real labels and cutoff\n",
    "    true_labels = train_test_dict[participant]['test']\n",
    "    cutoff = train_test_dict[participant]['cutoff']\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(start=cutoff, end=cutoff + len(true_labels)-1)\n",
    "    \n",
    "    assert len(predictions) == len(true_labels)\n",
    "    \n",
    "    # Save the predictions\n",
    "    prediction_dict[participant] = {'true_labels': true_labels, 'predictions': predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4fb7759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AS14.01     MSE = 0.81     RMSE = 0.83\n",
      "AS14.02     MSE = 1.11     RMSE = 2.22\n",
      "AS14.03     MSE = 0.57     RMSE = 0.39\n",
      "AS14.05     MSE = 0.46     RMSE = 0.38\n",
      "AS14.06     MSE = 0.74     RMSE = 1.17\n",
      "AS14.07     MSE = 1.23     RMSE = 2.68\n",
      "AS14.08     MSE = 0.86     RMSE = 1.27\n",
      "AS14.09     MSE = 0.81     RMSE = 0.98\n",
      "AS14.12     MSE = 0.64     RMSE = 0.70\n",
      "AS14.13     MSE = 1.01     RMSE = 1.40\n",
      "AS14.14     MSE = 0.46     RMSE = 0.50\n",
      "AS14.15     MSE = 0.23     RMSE = 0.20\n",
      "AS14.16     MSE = 0.52     RMSE = 0.58\n",
      "AS14.17     MSE = 0.50     RMSE = 0.55\n",
      "AS14.19     MSE = 0.72     RMSE = 0.80\n",
      "AS14.20     MSE = 0.33     RMSE = 0.33\n",
      "AS14.23     MSE = 0.63     RMSE = 1.29\n",
      "AS14.24     MSE = 0.41     RMSE = 0.46\n",
      "AS14.25     MSE = 0.42     RMSE = 0.39\n",
      "AS14.26     MSE = 0.80     RMSE = 0.92\n",
      "AS14.27     MSE = 0.76     RMSE = 0.95\n",
      "AS14.28     MSE = 0.79     RMSE = 0.87\n",
      "AS14.29     MSE = 0.75     RMSE = 0.76\n",
      "AS14.30     MSE = 0.32     RMSE = 0.15\n",
      "AS14.31     MSE = 0.08     RMSE = 0.08\n",
      "AS14.32     MSE = 0.90     RMSE = 1.16\n",
      "AS14.33     MSE = 1.09     RMSE = 1.97\n"
     ]
    }
   ],
   "source": [
    "for participant in prediction_dict:\n",
    "    true_labels = prediction_dict[participant]['true_labels']\n",
    "    predictions = prediction_dict[participant]['predictions']\n",
    "    \n",
    "    MSE = mean_absolute_error(true_labels, predictions)\n",
    "    RMSE = mean_squared_error(true_labels, predictions)\n",
    "    \n",
    "    print(f\"{participant}     MSE = {MSE:.2f}     RMSE = {RMSE:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "datamining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
